""" 
Still need to make change to louvainLNL.  Also, need to think about
difference between combinatorial and normalised here.  Have a feeling
normalised may have more physical meaning


"""

""" Full Stability - uses louvainLNL """

#import louvainLNL
import louvainLCL
import numpy as np
import scipy 
import scipy.sparse
import scipy.spatial.distance as ssd
import networkx as nx
import matplotlib.pyplot as plt
import csv
import pandas as pd
import proteingraph3.varinfo
import multiprocessing
import os


class Stability_run(object):
    """ Class which runs and holds the results of a Markov stability
    analysis of a protein.

    Parameters
    ----------
    protein: Protein
      Protein object to be analysed
    graph: the adjacency matrix of the protein generated by
      networkx 
    stability_type: full or linearised
      The form of stability to be used in the calculation
    precision: defines a threshold for the range of weights
      allowed in the laplacian exponential matrix of the full stability.
    louvain_runs: Number of optimisations of the Louvain algorithm to be 
      done at each Markov time.

      """

    def __init__(self, protein, precision=1e-9, louvain_runs=100):
          self.protein = protein
          self.graph = protein.graph
          self.precision = precision
          self.louvain_runs = louvain_runs

          
          self.stability_results = None
          self.timesteps = []
          #protein.graph is a networkx Graph() object that stores info in a dictionary

          self.louvain_ensemble = [] #just for testing



    def calculate_full_stability(self, time_array, calcVI=True):
        
        # stability_array = []
        # number_of_comms_array = []
        # community_id_array = []
        self.calcVI = calcVI

        timesteps = [element[0] for element in enumerate(time_array)]
        self.timesteps = timesteps


        #two-centre (bond) adjacency matrix
        A_bonds, G_bonds = generate_bond_matrices(self.protein)
        K_bonds = (A_bonds.T).dot(G_bonds).dot(A_bonds)

        #check for whether K is sparse
        if protein.angles:
            A_angles, G_angles = generate_angle_matrices(self.protein)
            K_angles = (A_angles.T).dot(G_angles).dot(A_angles)
        else:
            #just set angle stiffness matrix to zero
            K_angles = np.zeros([len(self.protein.atoms), len(self.protein.atoms)])
        
        if protein.dihedrals:
            A_dihedrals, G_dihedrals = generate_dihedral_matrices(self.protein)
            K_dihedrals = (A_dihedrals.T).dot(G_dihedrals).dot(A_dihedrals)
        else:
            #just set dihedral stiffness matrix to zero
            K_dihedrals = np.zeros([len(self.protein.atoms), len(self.protein.atoms)])
        
        K_total = K_bonds + K_angles + K_dihedrals

        """ May need to convert these to ndarrays - test"""
        diag = np.diag(K_total)
        adj = diag - K_total 
            

        no_of_nodes = adj.shape[0]

        avg_degree = np.sum(adj)/no_of_nodes

        
        PI = np.diag(np.ones(no_of_nodes)/no_of_nodes)


        stability_array = []
        number_of_comms_array = []
        community_id_array = []
        VI_array = []
    
        
        #uses louvainLNL
        for i,time in enumerate(time_array): #time is an array of times

            exponential = scipy.linalg.expm(-time*K_total/avg_degree)

            solution = np.dot(PI, exponential)

            #need to strip out matrix elements according to provided precision value
            solution = np.max(solution) * self.precision * np.round(solution/(np.max(solution)*self.precision))

            graph = find(solution) #find() is a helper function - see below

            (stability, number_of_comms, community_id, VI) = self.full_stability(graph)

            stability_array.append(stability)
            number_of_comms_array.append(number_of_comms)
            community_id_array.append(community_id)
            VI_array.append(VI)

            print ('Timestep ' + str(i+1) + ' of ' + str(len(time_array)) + ' completed.')            


        stability_results_frame = pd.DataFrame(
            {
                'Markov time' : time_array,
                'stability' : stability_array,
                'number_of_communities' : number_of_comms_array,
                'community_id' : community_id_array,
                'VI' : VI_array
            },
            index=timesteps,
        )

        self.stability_results = stability_results_frame
        

    def full_stability(self, graph):

        louvain_ensemble = []
        stability_partition_list = []
        number_of_comms_partition_list = []

        for i in range(self.louvain_runs):
            (stability, number_of_comms, community_id) = louvainLNL.stability(graph, 1, self.precision, 'w') #Still need to change this code in louvainLNL            
            louvain_ensemble.append(community_id)
            stability_partition_list.append(stability)
            number_of_comms_partition_list.append(number_of_comms)
            

        stability = max(stability_partition_list)
        index = stability_partition_list.index(max(stability_partition_list))
        number_of_comms = number_of_comms_partition_list[index]
        community_id = louvain_ensemble[index]

        if self.calcVI:
            VI = calculate_VI(louvain_ensemble)  # Added here
            return (stability, number_of_comms, community_id, VI) #will also need to return louvain ensemble
        
        else:
            VI = [] #seems a bit hacky, find a way to return different numbers of variables 
            return (stability, number_of_comms, community_id, VI)


        

    def calculate_linear_stability(self, time_array, calcVI=True):
       #uses louvainLCL        

        self.calcVI = calcVI

        timesteps = [element[0] for element in enumerate(time_array)]
        self.timesteps = timesteps

        #two-centre (bond) adjacency matrix
        A_bonds, G_bonds = generate_bond_matrices(self.protein)
        K_bonds = (A_bonds.T).dot(G_bonds).dot(A_bonds)
        print ("two-centre matrices done...")
        #check for whether K is sparse
        if self.protein.angles:
            A_angles, G_angles = generate_angle_matrices(self.protein)
            K_angles = (A_angles.T).dot(G_angles).dot(A_angles)
        else:
            #just set angle stiffness matrix to zero
            K_angles = np.zeros([len(self.protein.atoms), len(self.protein.atoms)])
        print ("three-centre matrices done...")
        
        if self.protein.dihedrals:
            A_dihedrals, G_dihedrals = generate_dihedral_matrices(self.protein)
            K_dihedrals = (A_dihedrals.T).dot(G_dihedrals).dot(A_dihedrals)
        else:
            #just set dihedral stiffness matrix to zero
            K_dihedrals = np.zeros([len(self.protein.atoms), len(self.protein.atoms)])
        print ("four-centre matrices done...")
        
        K_total = K_bonds + K_angles + K_dihedrals
        print(type(K_total))
        """ May need to convert these to ndarrays - test
        Think about memory here, no need to convert to full matrix 
        until required"""
        diag = K_total.diagonal()
        print(type(diag))
        adj = np.diag(diag) - K_total.toarray() #probably clean this up 
        print(type(adj))

        graph = find(adj) #need to test this

        stability_array = []
        number_of_comms_array = []
        community_id_array = []
        VI_array = []

        for i, time in enumerate(time_array): #time is an array of times

            (stability, number_of_comms, community_id, VI) = self.linear_stability(graph, time)

            stability_array.append(stability)
            number_of_comms_array.append(number_of_comms)
            community_id_array.append(community_id)
            VI_array.append(VI)

            print ('Timestep ' + str(i+1) + ' of ' + str(len(time_array)) + ' completed.')

        stability_results_frame = pd.DataFrame(
            {
                'Markov time' : time_array,
                'stability' : stability_array,
                'number_of_communities' : number_of_comms_array,
                'community_id' : community_id_array,
                'VI' : VI_array
            },
            index=timesteps,
        )

        self.stability_results = stability_results_frame            


    def linear_stability(self, graph, time):

        louvain_ensemble = []
        stability_partition_list = []
        number_of_comms_partition_list = []
        
        print("stability calc...")
        for i in range(self.louvain_runs):
            (stability, number_of_comms, community_id) = louvainLCL.stability(graph, time, self.precision) #remove weighted, not needed
            
            louvain_ensemble.append(community_id)
            stability_partition_list.append(stability)
            number_of_comms_partition_list.append(number_of_comms)
            

        stability = max(stability_partition_list)
        index = stability_partition_list.index(max(stability_partition_list))
        number_of_comms = number_of_comms_partition_list[index]
        community_id = louvain_ensemble[index]
        print("Louvain step finished...")

        if self.calcVI:
            VI = calculate_VI(louvain_ensemble) # Added here
            return (stability, number_of_comms, community_id, VI) # need to decide what to do with VI_mat

        else:
            VI = []  
            return (stability, number_of_comms, community_id, VI)




    def plot_stability(self):

        x = np.array(self.timesteps)
        y1 = np.array(self.stability_results.number_of_communities)
        y2 = np.array(self.stability_results.stability)
        y3 = np.array(self.stability_results.VI)

        ax1 = plt.subplot(211)
        ax1.plot(x, y1, 'r')
        ax1.set_ylabel('Number of communities')

        ax2 = ax1.twinx()
        ax2.plot(x, y2, 'g')
        ax2.set_ylabel('Stability')

        ax3 = plt.subplot(212)
        ax3.plot(x, y3, 'b')
        ax3.set_xlabel('Markov time (s)')
        ax3.set_ylabel('Variation of Information')

        plt.show()

    
    

    def csv_for_sankey(self, timesteps=[], filename=''):

        """ Enter an array of the timesteps you wish to use in the Sankey diagram and the filename of the output file """
        
        C = np.array(self.community_id_array)

        partitions = {}
        for n,t in enumerate(timesteps):

            comms = int(max(C[t,:]) + 1) # gives the index to loop over within a timestep (i.e. number of communities - 1)

            d={}
            for x in range(0, comms):
                d["{0}".format(x)] = []


            for i,k in enumerate(C[t,:]):
                for j in d.keys(): 
                    if k == int(j):
                        d[j].append(str(i))

            partitions["timestep {0}".format(t)] = d

        #Need now to generate a partition_list of 'values' between the communities in different timesteps
        #Number of timesteps again given by a and b

        partition_list = []
        for n,t in enumerate(timesteps): 
            

            initial_community =  partitions["timestep {0}".format(timesteps[n])] 
            final_community  =  partitions["timestep {0}".format(timesteps[n+1])]

            initial_comms = int(max(C[timesteps[n],:]) + 1)  
            final_comms = int(max(C[timesteps[n+1],:]) + 1)

            for i in range(0, initial_comms):
                for j in range(0, final_comms):
                    
                    initial_partition_list = initial_community[str(i)]
                    final_partition_list = final_community[str(j)]

                    value = len(set(initial_partition_list).intersection(final_partition_list))

                    each_tuple = ("T {0}: C {1}".format(timesteps[n],i), 
                            "T {0}: C {1}".format(timesteps[n+1], j),
                            value)
                    partition_list.append(each_tuple)

            if n+1 == len(timesteps) - 1:
                break

        final_partition_list = [value for value in partition_list if value[2] != 0]

        with open(filename,'w') as out: #change output file here
            csv_out=csv.writer(out)
            csv_out.writerow(['source','target', 'value'])

            for row in final_partition_list:
                csv_out.writerow(row)
     





def generate_bond_matrices(protein):
    """
    Returns the (sparse) m by n incidence matrix A for the two-centre
    interaction (i.e. the bonds) and the m by m diagonal matrix of
    force constants.
    """
    natoms = len(protein.atoms)
    nbonds = len(protein.bonds)

    A = np.zeros([nbonds, 3*natoms])
    force_constants = np.zeros(nbonds)
    for bond in protein.bonds:
        
        atom1_id = bond.atom1.id
        atom2_id = bond.atom2.id

        atom1_xyz = bond.atom1.xyz
        atom2_xyz = bond.atom2.xyz

        bond_length = np.linalg.norm(atom1_xyz - atom2_xyz)

        row = A[bond.id]
        row[[3*atom1_id, (3*atom1_id)+1, (3*atom1_id)+2]] = (atom1_xyz - atom2_xyz)/bond_length
        row[[3*atom2_id, (3*atom2_id)+1, (3*atom2_id)+2]] = (atom2_xyz - atom1_xyz)/bond_length

        forceconstant = bond.weight # this needs to change when force constants figured out
        force_constants[bond.id] = forceconstant

    A = scipy.sparse.csr_matrix(A)
    G = scipy.sparse.diags(force_constants) 

    return (A, G)


def generate_angle_matrices(protein):
    """
    Returns the (sparse) m by n incidence matrix for the three-centre
    interaction (i.e. the angles) and the m by m diagonal matrix of
    force constants.
    """

    #double check maths for this to be safe (particularly signs)

    natoms = len(protein.atoms)
    nangles = len(protein.angles)

    A = np.zeros([nangles, 3*natoms])
    force_constants = np.zeros(nangles)
    for angle in protein.angles:

        atom1_id = angle.atom1.id
        atom2_id = angle.atom2.id
        atom3_id = angle.atom3.id

        atom1_xyz = angle.atom1.xyz
        atom2_xyz = angle.atom2.xyz
        atom3_xyz = angle.atom3.xyz

        three_centre_length = np.linalg.norm(atom1_xyz - atom3_xyz)

        row = A[angle.id]
        row[[3*atom1_id, (3*atom1_id)+1, (3*atom1_id)+2]] = (atom2_xyz - atom3_xyz)/three_centre_length
        row[[3*atom2_id, (3*atom2_id)+1, (3*atom2_id)+2]] = -((atom2_xyz - atom1_xyz) + (atom2_xyz - atom3_xyz))/three_centre_length
        row[[3*atom3_id, (3*atom3_id)+1, (3*atom3_id)+2]] = (atom2_xyz - atom1_xyz)/three_centre_length

        forceconstant = angle.forceconstant
        force_constants[angle.id] = forceconstant
    
    A = scipy.sparse.csr_matrix(A)
    G = scipy.sparse.diags(force_constants)

    return (A,G)

def generate_dihedral_matrices(protein):
    """
    Returns the (sparse) m by n incidence matrix for the four-centre
    interaction (i.e. the dihedrals) and the m by m diagonal matrix of
    force constants.
    """

    #double check maths for this to be safe (particularly signs)

    natoms = len(protein.atoms)
    ndihedrals = len(protein.dihedrals)

    A = np.zeros([ndihedrals, 3*natoms])
    force_constants = np.zeros(ndihedrals)
    for dihedral in protein.dihedrals:
        
        atom1_id = dihedral.atom1.id
        atom2_id = dihedral.atom2.id
        atom3_id = dihedral.atom3.id
        atom4_id = dihedral.atom4.id

        atom1_xyz = dihedral.atom1.xyz
        atom2_xyz = dihedral.atom2.xyz
        atom3_xyz = dihedral.atom3.xyz
        atom4_xyz = dihedral.atom4.xyz

        four_centre_length = np.linalg.norm(atom1_xyz - atom4_xyz)

        row = A[dihedral.id]
        row[[3*atom1_id, (3*atom1_id)+1, (3*atom1_id)+2]] = -((atom1_xyz - atom3_xyz) + (atom4_xyz - atom2_xyz))/four_centre_length 
        row[[3*atom2_id, (3*atom2_id)+1, (3*atom2_id)+2]] = -((atom2_xyz - atom1_xyz) + (atom2_xyz - atom3_xyz) + (atom2_xyz - atom4_xyz))/four_centre_length
        row[[3*atom3_id, (3*atom3_id)+1, (3*atom3_id)+2]] = -((atom3_xyz - atom4_xyz) + (atom3_xyz - atom1_xyz) + (atom3_xyz - atom2_xyz))/four_centre_length
        row[[3*atom4_id, (3*atom4_id)+1, (3*atom4_id)+2]] = -((atom4_xyz - atom2_xyz) + (atom1_xyz - atom3_xyz))/four_centre_length

        forceconstant = dihedral.forceconstant
        force_constants[dihedral.id] = forceconstant

    A = scipy.sparse.csr_matrix(A)
    G = scipy.sparse.diags(force_constants)

    return (A, G)


def calculate_VI(louvain_ensemble):

    temp = varinfo.Varinfo(louvain_ensemble)
    temp.remove_repeats()

    if temp.VI == 0:
        return 0
    else:
        #parallelisation of outer loop in VI calculation (i.e. loop over partitions)
        pool = multiprocessing.Pool(os.cpu_count())
        result = pool.map(temp.parallel_partitions, range(temp.number_of_partitions))
        pool.close()
        pool.join()
        #result is list of tuples.  Convert to dictionary
        result_dict = dict(result)

        #Use dictionary to contruct numpy array
        VI_mat = np.zeros((temp.number_of_partitions, temp.number_of_partitions))
        for i in range(temp.number_of_partitions):
            VI_mat[i] = result_dict[i]
        
        
        VI_mat_full = np.zeros((temp.number_of_partitions, len(temp.indices)))

        for i in range(temp.number_of_partitions):
            VI_mat_full[i] = VI_mat[i, np.array(temp.indices)]
        
        VI_mat_full = VI_mat_full[np.array(temp.indices)]

        VI_mat = VI_mat_full + np.transpose(VI_mat_full)

        VI = np.mean(ssd.squareform(VI_mat))

        return VI # decide on VI_mat


# helper function - replicates Matlab's find function.  Takes ndarray as argument.
def find(matrix):

    unweighted_partition_list = list(zip(np.where(matrix > 0))) #gives [row, col] without values

    edge_partition_list = np.where(matrix > 0)
    partition_list_of_indices = list(zip(edge_partition_list[0], edge_partition_list[1])) #i.e. [(0, 1), (1, 0), (1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]

    values = [matrix[element[0]][element[1]] for element in partition_list_of_indices] #extracts weighting values using indices above

    graph = np.array([unweighted_partition_list[0][0], unweighted_partition_list[1][0], values], dtype=np.float64) #bit ugly, should fix

    return graph




